---
title: "Tarea 3. LSH y Entity matching"
output: html_notebook
---


En este ejemplo veremos como usar LSH 
para encontrar registros
que se refieren al mismo elemento pero están en distintas tablas, 
y pueden diferir en cómo están registrados (entity matching). Vamos a
usar funciones del paquete *textreuse*, aunque puedes usar
también las funciones de las notas.

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching. **El objetivo es parear las dos fuentes para
identificar artículos que se presenteron en las dos referencias.**


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../datos/entity_matching/ACM.csv')
dbl <- read_csv('../datos/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta 1**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer? Si cada tabla contuviera unos 2 millones de documentos, ¿qué tan 
factible sería hacer todas las posibles comparaciones?

## Tejas y hashing

Vamos a poner todos los documentos en una sola lista. Aunque al final
encontremos elementos de la misma fuente en la misma cubeta, podemos
filtrar estos.

```{r}
acm_1 <- acm |> select(id, title, authors) |> 
  mutate(texto = paste(title, authors, sep = "    ")) |> 
  mutate(origen = "ACM") |> 
  mutate(id = as.character(id))
dbl_1 <- dbl |> select(id, title, authors) |> 
  mutate(texto = paste(title, authors, sep = "    ")) |> 
  mutate(origen = "DBL")
acm_dbl <- bind_rows(acm_1, dbl_1)
```

**Pregunta 2**: ¿por qué definimos el texto incluyendo algún espacio en blanco entre título y autor?
¿Qué otra estrategia se te ocurre para convertir en tejas?

**Pregunta 3**: cuántas comparaciones tendrías que hacer si calcularas
la similitud entre todos los posibles pares?

```{r}
# función de las notas
calcular_tejas <- function(x, k = 4, lowercase = FALSE){
  tokenizers::tokenize_character_shingles(x, n = k, lowercase = lowercase,
    simplify = TRUE, strip_non_alpha = FALSE)
}
generar_hash <- function(){
  r <- as.integer(stats::runif(1, 1, 2147483647))
  funcion_hash <- function(tejas){
        digest::digest2int(tejas, seed = r) 
  }
  funcion_hash
}
```

En este caso escogemos 10 hashes,
tejas de tamaño 4, y usamos sólo título y autor.


```{r}
set.seed(88345)
# usar funciones de textreuse (que hace hash de las tejas directamente)
hashes <- map(1:4, ~ generar_hash())
# el siguiente devuelve un objeto con los minhashes calculados
corpus <- acm_dbl |> 
  mutate(texto = str_to_lower(texto))
corpus_tejas <- corpus |> 
  mutate(tejas = map(texto, ~ calcular_tejas(.x, k = 5)))
```

Por ejemplo, para el primer documento tenemos el contenido y los minhashes calculados:

```{r}
corpus_tejas$texto[[1]]
corpus_tejas$tejas[[1]]
```

Ahora calculamos minhashes

```{r}
construir_firmas <- function(hashes, tejas){
  tibble(hash_num = 1:length(hashes), 
         firma = map_int(hashes, \(h) min(h(tejas)))
  )
}
docs_firmas <- corpus_tejas |> 
  mutate(firma = map(tejas, ~ construir_firmas(hashes, .x))) |> 
  select(id, firma) |> 
  unnest(firma) |> 
  mutate(cubeta = paste(hash_num, firma, sep = "-")) |> 
  select(id, cubeta)
docs_firmas
```

 Ahora agrupamos por cubeta y filtramos:

```{r}
docs_cubetas_tbl <- 
  docs_firmas |> 
  group_by(cubeta) |> 
  summarise(docs = list(id)) |> 
  mutate(num_docs = map_int(docs, length)) 
docs_cubetas_filt_tbl <- docs_cubetas_tbl |> 
  filter(num_docs > 1)
nrow(docs_cubetas_filt_tbl)
```



## Examinar pares candidatos

Ahora extraemos pares similares. 

```{r}
pares_tbl <- docs_cubetas_filt_tbl |> 
  mutate(pares_cand = map(docs, ~ combn(.x, 2, simplify = FALSE))) |> 
  select(cubeta, pares_cand) |> 
  unnest(pares_cand) |> 
  unnest_wider(pares_cand, names_sep = "_") |> 
  left_join(corpus_tejas |>
              select(pares_cand_1 = id, tejas_1 = tejas, origen_1 = origen)) |> 
  left_join(corpus_tejas |> 
              select(pares_cand_2 = id, tejas_2 = tejas, origen_2 = origen)) |> 
  mutate(score = map2_dbl(tejas_1, tejas_2, ~ sim_jaccard(.x, .y))) 
pares_tbl
```

Quitamos pares de la misma fuente:

```{r}
pares_tbl <- filter(pares_tbl, origen_1 == "ACM", origen_1 != origen_2) |> 
  unique()
pares_tbl <- pares_tbl |> select(pares_cand_1, pares_cand_2, origen_1, origen_2, score)
```



**Pregunta 4**: explica cómo se calcula la columna *score* en la tabla de candidatos,
y da unos ejemplos.


**Pregunta 5**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)? Compara con el total
de comparaciones que es posible hacer entre estas dos tablas.



**Pregunta 6**: 
¿Cuántos pares candidatos obtuviste?
Examina algunos elementos con similitud uno o cercana a uno. ¿Se refieren al
mismo artículo en las dos fuentes? 



## Examinar resultados

**Pregunta 8**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.


**Pregunta 9**: propón un punto de corte de similitud para la tabla de arriba, según tus
observaciones de la pregunta anterior.

```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
candidatos_filt <- filter(pares_tbl, score > 0.50)
tail(candidatos_filt)
```

**Pregunta 10**: ¿cuántos pares candidatos obtuviste al final?


## Evaluación de resultados

 Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.


```{r}
mapping <- read_csv("../datos/entity_matching/DBLP-ACM_perfectMapping.csv")
```

Crea variables apropiadas para hacer join de los verdaderos matches con tus candidatos:

```{r}
candidatos_filt <- candidatos_filt |> mutate(idDBLP = ifelse(str_detect(pares_cand_1, "^[0-9]*$"), pares_cand_2, pares_cand_1))
candidatos_filt <- candidatos_filt |> mutate(idACM = ifelse(str_detect(pares_cand_1, "^[0-9]*$"), pares_cand_1, pares_cand_2))
```

Podemos calcular el número de pares verdaderos que son candidatos (recuperados), el número de pares
candidatos que son candidatos pero no son pares verdaderos, por ejemplo:

```{r}
mapping <- mapping |> mutate(idACM = as.character(idACM))
ambos <- inner_join(candidatos_filt, mapping)
nrow(candidatos_filt)
nrow(ambos)
```

*Pregunta 11 *: Evalúa precisión y recall de tu método. Para distintas aplicaciones que te
puedas imaginar, ¿qué tan buenos son estos resultados? ¿Qué consideras
mejor en este punto, tener precisión o recall alto? 

```{r}
precision <- 
precision
recall <- 
recall
```


## Análisis de errores

Considera algunos casos que fallamos en recuperar como candidatos. Examina algunos
de los siguientes pares:

```{r}
anti_join(mapping, candidatos_filt) 
```

**Pregunta 11**: Considerando estos errores, ¿qué se te ocurre para mejorar el método?
